{
 "metadata": {
  "name": "",
  "signature": "sha256:199dfa1b061ae90692329271fd71bfd7c2ac7a5b668a90020ee8b01c02a3af19"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mxnet import nd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scalar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate two scalars\n",
      "x = nd.array([3.0])\n",
      "y = nd.array([2.0])\n",
      "# Add them\n",
      "print('x + y = ', x + y)\n",
      "# Multiply them\n",
      "print('x * y = ', x * y)\n",
      "# Divide x by y\n",
      "print('x / y = ', x / y)\n",
      "# Raise x to the power y.\n",
      "print('x ** y = ', nd.power(x,y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('x + y = ', \n",
        "[ 5.]\n",
        "<NDArray 1 @cpu(0)>)\n",
        "('x * y = ', \n",
        "[ 6.]\n",
        "<NDArray 1 @cpu(0)>)\n",
        "('x / y = ', \n",
        "[ 1.5]\n",
        "<NDArray 1 @cpu(0)>)\n",
        "('x ** y = ', \n",
        "[ 9.]\n",
        "<NDArray 1 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Convert ndarray to python floats"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.asscalar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "3.0"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Vectors"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u = nd.arange(4)\n",
      "print('u = ', u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('u = ', \n",
        "[ 0.  1.  2.  3.]\n",
        "<NDArray 4 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The length of a vector is called its dimetinon. The number of axes is called its order"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(u))\n",
      "print(u.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n",
        "(4L,)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Matrices. Scalar order 0, vector order 1, matrices order 2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = nd.arange(20).reshape((5, 4))\n",
      "print('A = ', A)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('A = ', \n",
        "[[  0.   1.   2.   3.]\n",
        " [  4.   5.   6.   7.]\n",
        " [  8.   9.  10.  11.]\n",
        " [ 12.  13.  14.  15.]\n",
        " [ 16.  17.  18.  19.]]\n",
        "<NDArray 5x4 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('A[2, 3] = ', A[2, 3])\n",
      "print('row 2', A[2, :])\n",
      "print('column 3', A[:, 3])\n",
      "A.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('A[2, 3] = ', \n",
        "[ 11.]\n",
        "<NDArray 1 @cpu(0)>)\n",
        "('row 2', \n",
        "[  8.   9.  10.  11.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('column 3', \n",
        "[  3.   7.  11.  15.  19.]\n",
        "<NDArray 5 @cpu(0)>)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "\n",
        "[[  0.   4.   8.  12.  16.]\n",
        " [  1.   5.   9.  13.  17.]\n",
        " [  2.   6.  10.  14.  18.]\n",
        " [  3.   7.  11.  15.  19.]]\n",
        "<NDArray 4x5 @cpu(0)>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tensors. Vectors are first-order tensors, matrices are second-order tensors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = nd.arange(24).reshape((2, 3, 4))\n",
      "print('X.shape =', X.shape)\n",
      "print('X =', X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('X.shape =', (2L, 3L, 4L))\n",
        "('X =', \n",
        "[[[  0.   1.   2.   3.]\n",
        "  [  4.   5.   6.   7.]\n",
        "  [  8.   9.  10.  11.]]\n",
        "\n",
        " [[ 12.  13.  14.  15.]\n",
        "  [ 16.  17.  18.  19.]\n",
        "  [ 20.  21.  22.  23.]]]\n",
        "<NDArray 2x3x4 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u = nd.array([1, 2, 4, 8])\n",
      "v = nd.ones_like(u) * 2\n",
      "print('u =', u)\n",
      "print('v =', v)\n",
      "print('u + v', u + v)\n",
      "print('u - v', u - v)\n",
      "print('u * v', u * v)\n",
      "print('u / v', u / v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('u =', \n",
        "[ 1.  2.  4.  8.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('v =', \n",
        "[ 2.  2.  2.  2.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('u + v', \n",
        "[  3.   4.   6.  10.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('u - v', \n",
        "[-1.  0.  2.  6.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('u * v', \n",
        "[  2.   4.   8.  16.]\n",
        "<NDArray 4 @cpu(0)>)\n",
        "('u / v', \n",
        "[ 0.5  1.   2.   4. ]\n",
        "<NDArray 4 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "B = nd.ones_like(A) * 3\n",
      "print('B =', B)\n",
      "print('A + B =', A + B)\n",
      "print('A * B =', A * B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('B =', \n",
        "[[ 3.  3.  3.  3.]\n",
        " [ 3.  3.  3.  3.]\n",
        " [ 3.  3.  3.  3.]\n",
        " [ 3.  3.  3.  3.]\n",
        " [ 3.  3.  3.  3.]]\n",
        "<NDArray 5x4 @cpu(0)>)\n",
        "('A + B =', \n",
        "[[  3.   4.   5.   6.]\n",
        " [  7.   8.   9.  10.]\n",
        " [ 11.  12.  13.  14.]\n",
        " [ 15.  16.  17.  18.]\n",
        " [ 19.  20.  21.  22.]]\n",
        "<NDArray 5x4 @cpu(0)>)\n",
        "('A * B =', \n",
        "[[  0.   3.   6.   9.]\n",
        " [ 12.  15.  18.  21.]\n",
        " [ 24.  27.  30.  33.]\n",
        " [ 36.  39.  42.  45.]\n",
        " [ 48.  51.  54.  57.]]\n",
        "<NDArray 5x4 @cpu(0)>)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = 2\n",
      "x = nd.ones(3)\n",
      "y = nd.zeros(3)\n",
      "print(x.shape)\n",
      "print(y.shape)\n",
      "print((a * x).shape)\n",
      "print((a * x + y).shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3L,)\n",
        "(3L,)\n",
        "(3L,)\n",
        "(3L,)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sums and Means"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sum on vector\n",
      "print(nd.sum(u))\n",
      "# sum on matrices\n",
      "print(nd.sum(A))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 15.]\n",
        "<NDArray 1 @cpu(0)>\n",
        "\n",
        "[ 190.]\n",
        "<NDArray 1 @cpu(0)>\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mean = sum/#elements\n",
      "print(nd.mean(A))\n",
      "print(nd.sum(A) / A.size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 9.5]\n",
        "<NDArray 1 @cpu(0)>\n",
        "\n",
        "[ 9.5]\n",
        "<NDArray 1 @cpu(0)>\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Dot products\n",
      "$u^TV=\\Sigma_{i=1}^du_i\\cdot v_i$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nd.dot(u, v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "\n",
        "[ 30.]\n",
        "<NDArray 1 @cpu(0)>"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The dot product is equivalent to perform an element-wise multplication and then sum."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nd.sum(u * v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "\n",
        "[ 30.]\n",
        "<NDArray 1 @cpu(0)>"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Matrix vector products"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nd.dot(A,u)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "\n",
        "[  34.   94.  154.  214.  274.]\n",
        "<NDArray 5 @cpu(0)>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mxnet as mx\n",
      "A_gpu = A.as_in_context(mx.gpu(0))\n",
      "u_gpu = u.as_in_context(mx.gpu(0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nd.dot(A_gpu,u_gpu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "\n",
        "[  34.   94.  154.  214.  274.]\n",
        "<NDArray 5 @gpu(0)>"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = nd.ones(shape=(3, 4)).as_in_context(mx.gpu(0))\n",
      "B = nd.ones(shape=(4, 5)).as_in_context(mx.gpu(0))\n",
      "nd.dot(A, B)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "\n",
        "[[ 4.  4.  4.  4.  4.]\n",
        " [ 4.  4.  4.  4.  4.]\n",
        " [ 4.  4.  4.  4.  4.]]\n",
        "<NDArray 3x5 @gpu(0)>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Norm $\\| \\cdot \\|$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In fact, the Euclidean distance $\\sqrt{x_1^2 + ... + x_n^2}$ is a norm. Specifically it\u2019s the \u21132-norm. An analogous computation, performed over the entries of a matrix, e.g. $\\sqrt{\\Sigma_{i,j}a_{ij}^2}$, is called the Frobenius norm. More often, in machine learning we work with with the squared \u21132 norm (notated \u21132). We also commonly work with the \u21131 norm. The \u21131 norm is simply the sum of the absolute values. It has the convenient property of placing less emphasis on outliers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# To calculate l2 norm, we can call nd.norm().\n",
      "print(nd.norm(u))\n",
      "# To calculate the L1 norm we can call nd.sum(nd.abs(u))\n",
      "print(nd.sum(nd.abs(u)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ 9.21954441]\n",
        "<NDArray 1 @cpu(0)>\n",
        "\n",
        "[ 15.]\n",
        "<NDArray 1 @cpu(0)>\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Specical Definite Matrix\n",
      "These are matrices that have the nice property where $x^TMx > 0$ whenever x \\neq 0. Intuitively, they are a generalization of the quared norm of a vector $\\|x\\|^2 =x^Tx$. It is easy to check that whenever $M = A^TA$, this holds since there $x^TMx = x^TA^TAx = \\|Ax\\|^2$. There is a"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}